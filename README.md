# PRODIGY_ML_4
# Hand Gesture Recognition using CNN âœ‹ğŸ¤–

## Overview
This project implements a **Hand Gesture Recognition** system using a **Convolutional Neural Network (CNN)** trained on the **LeapGestRecog** dataset. The model can classify different hand gestures, making it useful for applications like human-computer interaction, gaming, and assistive technologies.

## Features
âœ… **Preprocessing**: Image resizing, grayscale conversion, and normalization.  
âœ… **Model Architecture**: CNN-based deep learning model for gesture recognition.  
âœ… **Real-time Prediction**: Uses OpenCV for live gesture recognition.  
âœ… **Performance Optimization**: Data augmentation and hyperparameter tuning.  

## Dataset
**LeapGestRecog Dataset**: A collection of grayscale hand gesture images, categorized into multiple gesture classes. Ensure that the dataset is downloaded and placed in the appropriate directory.

Dataset Path:  
`C:\Users\navan\Downloads\HAND GESTURE\leapGestRecog`

## Installation
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/hand-gesture-recognition.git
cd hand-gesture-recognition
```
### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```
### 3ï¸âƒ£ Run the Training Script
```bash
python train_model.py
```
### 4ï¸âƒ£ Test the Model
```bash
python test_model.py
```
### 5ï¸âƒ£ Real-time Gesture Detection
```bash
python real_time_gesture.py
```

## Model Training
- The CNN model is trained using **TensorFlow/Keras**.
- Optimized using **Adam optimizer**.
- Evaluation using **accuracy, precision, recall, and confusion matrix**.

## Results & Insights
ğŸ“Œ **Gesture recognition accuracy** achieved: ~XX% (based on testing).  
ğŸ“Œ **Key learning**: Gesture classification requires careful feature extraction and lighting conditions impact recognition.  
ğŸ“Œ **Future improvements**: Exploring transformer-based vision models for better accuracy.  

## Folder Structure
```
â”œâ”€â”€ leapGestRecog/          # Dataset Folder
â”œâ”€â”€ models/                 # Trained Model Files
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_model.py      # Model Training Script
â”‚   â”œâ”€â”€ test_model.py       # Model Testing Script
â”‚   â”œâ”€â”€ real_time_gesture.py # Live Gesture Recognition
â”œâ”€â”€ README.md               # Project Documentation
â””â”€â”€ requirements.txt        # Dependencies
```

## Contributors
- **[Your Name]** â€“ AI/ML Developer ğŸ¤–

## License
ğŸ“œ This project is licensed under the **MIT License**.

---

ğŸ’¡ **Letâ€™s Make AI More Interactive!** If you find this useful, feel free to â­ the repo and contribute! ğŸš€
